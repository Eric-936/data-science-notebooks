{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN with transfer learning\n",
        "\n",
        "In this notebook, I'll build a CNN model to detect the American Sign Language (ASL). Then, try to use transfer learning (ResNet-50) to improve the performance.\n",
        "\n",
        "**Key Words:** PyTorch, CNN, ResNet-50"
      ],
      "metadata": {
        "id": "OUyvGFcozrAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and Set up"
      ],
      "metadata": {
        "id": "DTrQ0JVODgdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "fJ4_XGyQIaaN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "DATASET_PATH = '/content/drive/MyDrive/machine-learning/assignments/midterm-project/midterm-project-individual/ASL-data'\n",
        "batch_size = 128\n",
        "torch.manual_seed(936)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrTvuuhTMOmK",
        "outputId": "6e0f01e8-ab43-449b-b5ec-f6db8cd295a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e57a809e430>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d9sHjhFIdXz",
        "outputId": "9a235c91-396c-4b32-c9d9-0b451bb23fb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ro3OkTpKa6L",
        "outputId": "1e13adef-df86-462f-cc90-42a91581b830"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "This ASL dataset was made by my group. It only includes letters from A to E."
      ],
      "metadata": {
        "id": "j7X7sVrsJK0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_normal = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Approximately between -1 an 1\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(root=os.path.join(DATASET_PATH, \"train\"), transform=transform_normal)\n",
        "val_data = datasets.ImageFolder(root=os.path.join(DATASET_PATH, \"val\"), transform=transform_normal)\n",
        "test_data = datasets.ImageFolder(root=os.path.join(DATASET_PATH, \"test\"), transform=transform_normal)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "uyXFXOtrJMy2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN\n",
        "\n",
        "I'm going to build a CNN model with 2 convolution layers."
      ],
      "metadata": {
        "id": "9bl20z_i2A36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a CNN class\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_filters=[16, 32], dropout=0.2):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.convol_1 = nn.Conv2d(3, num_filters[0], kernel_size=3, padding=1)\n",
        "        self.convol_2 = nn.Conv2d(num_filters[0], num_filters[1], kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.func_1 = nn.Linear(num_filters[1] * 8 * 8, 128)\n",
        "        self.func_2 = nn.Linear(128, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convol_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.convol_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, self.num_filters[1] * 8 * 8)\n",
        "        x = self.func_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.func_2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UJFXclV3p96P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare to train the model"
      ],
      "metadata": {
        "id": "OiW7DbBA1Qxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = MyCNN()\n",
        "my_model = my_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(my_model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "X5QiTeYe1SmU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model\n",
        "\n",
        "While training the model, we also do validation in each epoch. And use early stopping to avoid overfitting."
      ],
      "metadata": {
        "id": "yINI1xAs1k3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do validation during training\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = float(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    return val_loss / len(val_loader) # Return average loss in one epoch"
      ],
      "metadata": {
        "id": "f4QePgMq4_NN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(my_model, train_loader, val_loader, criterion, optimizer):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # Variables for early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 3 # Three times for no improvement\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(100):\n",
        "        my_model.train()\n",
        "        train_loss = float(0)\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = my_model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Get loss on training set\n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Get loss on validation set\n",
        "        val_loss = validate(my_model, val_loader, criterion)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            counter = 0\n",
        "            torch.save(my_model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            counter += 1\n",
        "\n",
        "            if counter >= patience:\n",
        "                break"
      ],
      "metadata": {
        "id": "BqWLf-0W1msl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train(my_model, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dGT85F8hGpyQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "jkzsvoXt6M8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(my_model, val_loader):\n",
        "    my_model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = my_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "print(f'Accuracy: {evaluate(my_model, val_loader):.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D42wdZ3q5apW",
        "outputId": "cf557c55-3070-49d3-a149-eae13a1708ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy 85.00%"
      ],
      "metadata": {
        "id": "gnQbACJWI3Kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tune hyperparameters"
      ],
      "metadata": {
        "id": "4SZcDc9a1p8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters we are going to tune:\n",
        "\n",
        "- Batch size\n",
        "- Dropout or not\n",
        "- Number of filters\n",
        "\n",
        "We make a tune grid to tune them all."
      ],
      "metadata": {
        "id": "uMIv2_0S1yJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build tuning grid\n",
        "batch_sizes = [32, 64]\n",
        "dropouts = [0.2, 0.5]\n",
        "filter_sets = [[16, 32], [32, 64]]\n",
        "\n",
        "all_grid = list(itertools.product(batch_sizes, dropouts, filter_sets))"
      ],
      "metadata": {
        "id": "WRdCEcYozz3T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune\n",
        "tune_result = []\n",
        "best_accuracy = float(0)\n",
        "\n",
        "for batch_size, dropout, filters in tqdm(all_grid):\n",
        "    train_loader_tune = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader_tune = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "    my_model_tune = MyCNN(num_filters=filters, dropout=dropout)\n",
        "    my_model_tune = my_model_tune.to(device)\n",
        "\n",
        "    optimizer_tune = torch.optim.Adam(my_model_tune.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model_train(my_model_tune, train_loader_tune, val_loader_tune, criterion, optimizer_tune)\n",
        "\n",
        "    eval_tune = evaluate(my_model_tune, val_loader_tune)\n",
        "\n",
        "    if eval_tune > best_accuracy:\n",
        "        torch.save(my_model_tune.state_dict(), 'best_model_tune.pth')\n",
        "        best_accuracy = eval_tune\n",
        "\n",
        "    tune_result.append((batch_size, dropout, filters, eval_tune))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqJZQOIWCIPw",
        "outputId": "a5fe2fab-f4e8-4d49-9563-5060cf0d2166"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [08:51<00:00, 66.40s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the table of tuning result\n",
        "for batch_size, dropout, filters, eval_tune in tune_result:\n",
        "    print(f'Batch size: {batch_size}, Dropout: {dropout}, Number of filters: {filters}, Accuracy: {eval_tune:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcHht2UvTOWk",
        "outputId": "5a27f856-0f42-42a7-a323-cbacf3dafc93"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 32, Dropout: 0.2, Number of filters: [16, 32], Accuracy: 85.00%\n",
            "Batch size: 32, Dropout: 0.2, Number of filters: [32, 64], Accuracy: 95.00%\n",
            "Batch size: 32, Dropout: 0.5, Number of filters: [16, 32], Accuracy: 90.00%\n",
            "Batch size: 32, Dropout: 0.5, Number of filters: [32, 64], Accuracy: 91.67%\n",
            "Batch size: 64, Dropout: 0.2, Number of filters: [16, 32], Accuracy: 76.67%\n",
            "Batch size: 64, Dropout: 0.2, Number of filters: [32, 64], Accuracy: 93.33%\n",
            "Batch size: 64, Dropout: 0.5, Number of filters: [16, 32], Accuracy: 83.33%\n",
            "Batch size: 64, Dropout: 0.5, Number of filters: [32, 64], Accuracy: 88.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best hyper-parameters are:\n",
        "\n",
        "- Batch size: 32\n",
        "- Dropout: 0.2\n",
        "- Number of filters: [32, 64]\n",
        "- Accuracy: 95.00%"
      ],
      "metadata": {
        "id": "5Zbd31LljOFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN with ResNet-50\n",
        "\n",
        "Get rid of my own convolution layer. Use ResNet-50 as a pre-trained model. Fine-tune the last layer (layer 4)."
      ],
      "metadata": {
        "id": "Wj3rUvI8-28R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization\n",
        "\n",
        "Normalize the data with ResNet requirement."
      ],
      "metadata": {
        "id": "mS-NRw2XDWwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_resnet = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data_resnet = datasets.ImageFolder(root=os.path.join(DATASET_PATH, \"train\"), transform=transform_resnet)\n",
        "val_data_resnet = datasets.ImageFolder(root=os.path.join(DATASET_PATH, \"val\"), transform=transform_resnet)\n",
        "test_data_resnet = datasets.ImageFolder(root=os.path.join(DATASET_PATH, \"test\"), transform=transform_resnet)\n",
        "\n",
        "train_loader_resnet = DataLoader(train_data_resnet, batch_size=batch_size, shuffle=True)\n",
        "val_loader_resnet = DataLoader(val_data_resnet, batch_size=batch_size)\n",
        "test_loader_resnet = DataLoader(test_data_resnet, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "tAM6DQRHDmfm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the ResNet-50 and modify it."
      ],
      "metadata": {
        "id": "ja9WTSuOEyCt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57d1fc9a",
        "outputId": "0247b492-e40e-4259-fbe1-65dd7630aeb9"
      },
      "source": [
        "# Load ResNet-50\n",
        "resnet_model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all parameters first\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last block (layer4) for fine-tuning\n",
        "for param in resnet_model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Replace the final fully connected layer with two layers (Hidden + Output)\n",
        "num_features = resnet_model.fc.in_features\n",
        "hidden_layer_size = 128\n",
        "\n",
        "resnet_model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, hidden_layer_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(hidden_layer_size, 5)\n",
        ")\n",
        "\n",
        "resnet_model = resnet_model.to(device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model."
      ],
      "metadata": {
        "id": "2JCPWAfpE4UC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "699accba"
      },
      "source": [
        "# Train the model\n",
        "criterion_resnet = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = torch.optim.Adam(resnet_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train using the previously defined training function\n",
        "model_train(resnet_model, train_loader_resnet, val_loader_resnet, criterion_resnet, optimizer_resnet)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model."
      ],
      "metadata": {
        "id": "hZIgQPCeEwJr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeb96dcd",
        "outputId": "b9df1122-9134-45bd-b084-190fff7c3967"
      },
      "source": [
        "# Evaluate the model\n",
        "# Load the best weights saved during training\n",
        "resnet_model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Validation set\n",
        "accuracy = evaluate(resnet_model, val_loader_resnet)\n",
        "print(f'ResNet-50 Accuracy on Validation set: {accuracy:.2f}%')\n",
        "\n",
        "# Test set\n",
        "accuracy = evaluate(resnet_model, test_loader_resnet)\n",
        "print(f'ResNet-50 Accuracy on Test set: {accuracy:.2f}%')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-50 Accuracy on Validation set: 96.67%\n",
            "ResNet-50 Accuracy on Test set: 91.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b22b4986",
        "outputId": "d3acb780-3392-4aa8-d648-bf955acf57be"
      },
      "source": [
        "# Calculate AUC\n",
        "y_probs = []\n",
        "y_true_auc = []\n",
        "\n",
        "resnet_model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader_resnet:\n",
        "        images = images.to(device)\n",
        "        # We need true labels on CPU for sklearn\n",
        "        y_true_auc.extend(labels.numpy())\n",
        "\n",
        "        outputs = resnet_model(images)\n",
        "        # Apply softmax to get probabilities\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "# Calculate Macro-Average AUC (One-vs-Rest)\n",
        "auc_score = roc_auc_score(y_true_auc, y_probs, multi_class='ovr', average='macro')\n",
        "print(f\"ResNet-50 Macro AUC: {auc_score:.4f}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-50 Macro AUC: 0.9865\n"
          ]
        }
      ]
    }
  ]
}